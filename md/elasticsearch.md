# Apache Lucene将文档写入索引的所有信息组织为倒排索引（Inverted index）的结构形式。倒排索引是一种将词项映射到文档的数据结构，
# 他与传统的关系型数据库工作方式不同。你可以认为倒排索引是面向此项而不是面向文档的。

```bash
文档id为1
GET smart_sourcing_system_company_search_index/_analyze?pretty=true
{
    "analyzer":"ik_max_word",
    "text": "中华人民共和国"
}
```
# 分词结果 ["中华人民共和国","中华人民", "中华","华人","人民共和国","人民","共和国","共和", "国"]

```bash
文档id为2
GET smart_sourcing_system_company_search_index/_analyze?pretty=true
{
    "analyzer":"ik_max_word",
    "text": "中华人民共和国国歌"
}
```
# 分词结果 ["中华人民共和国","中华人民","中华","华人","人民共和国","人民","共和国","共和", "国", "国歌"]
```bash
文档id为3
GET smart_sourcing_system_company_search_index/_analyze?pretty=true
{
    "analyzer":"ik_max_word",
    "text": "中央政府人民大会堂"
}
```
# 分词结果 ["中央政府", "中央","政府","人民大会堂","人民大会", "人民", "大会堂", "大会","会堂"]

#倒排索引
```text
     词项         数量           文档id
中华人民共和国       2            <1><2>
  中华人民          2            <1><2>
  中华             2            <1><2>
  华人             2            <1><2>
  人民共和国        2            <1><2>
  人民             3            <1><2><3>
  共和国           2            <1><2>
  共和             2            <1><2>
  共和             2            <1><2>
  国               2           <1><2>
  国歌             1            <2>
  中央政府          1            <3>
  中央             1            <3>
  政府             1            <3>
  人民大会堂        1            <3>
  人民大会          1            <3>
  大会堂            1            <3>
  大会             1            <3>
  会堂             1            <3>
```
# 这样每个词项指向指向出现的文档以及文档数量。当然还有其他信息比如这个词在多少个文档中出现过。
# 当执行全文搜索操作时，先使用分词器对搜索的字符进行分词，把各个词项那个该索引文档进行匹配。使用TF/IDF算法打分。
# 每个索引由多个段（segment）组成，每个段写入一次但是查询多次。索引期间，一个段创建之后就不能进行修改。
# 例如，当文档更新时，旧版本的文档将会被标记为删除，新版本的文档在新的segment中建立索引。
# 也许新旧版本的文档都会本检索到，但是旧版本的文档会在最终结果返回时被移除。
# 如果是删除文档则标记为删除，也许新旧版本的文档都会本检索到，但是旧版本的文档会在最终结果返回时被移除。

```text
写到磁盘的倒序索引是不变的：自从写到磁盘就再也不变。 这会有很多好处：
 不需要添加锁。如果你从来不用更新索引，那么你就不用担心多个进程在同一时间改变索引。
 一旦索引被内核的文件系统做了Cache，它就会待在那因为它不会改变。只要内核有足够的缓冲空间，
 绝大多数的读操作会直接从内存而不需要经过磁盘。这大大提升了性能。
 其他的缓存(例如fiter cache)在索引的生命周期内保持有效，它们不需要每次数据修改时重构，因为数据不变。
 写一个单一的大的倒序索引可以让数据压缩，减少了磁盘I/O的消耗以及缓存索引所需的RAM。
当然，索引的不变性也有缺点。如果你想让新修改过的文档可以被搜索到，你必须重新构建整个索引。
这在一个index可以容纳的数据量和一个索引可以更新的频率上都是一个限制。
```
# [搜索过程](https://github.com/lucky-xin/Learning/blob/gh-pages/image/elasticsearch-search-pas.png)
```text
查询阶段包含以下三个步骤:
客户端发送一个 search 请求到 Node 3 ， Node 3 会创建一个大小为 from + size 的空优先队列。
Node 3 将查询请求转发到索引的每个主分片或副本分片中。每个分片在本地执行查询并添加结果到大小为 from + size 的本地有序优先队列中。
每个分片返回各自优先队列中所有文档的 ID 和排序值给协调节点，也就是 Node 3 ，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。
当一个搜索请求被发送到某个节点时，这个节点就变成了协调节点。 这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，
这个结果集合会返回给客户端。
第一步是广播请求到索引中每一个节点的分片拷贝。就像 document GET requests 所描述的， 查询请求可以被某个主分片或某个副本分片处理， 
这就是为什么更多的副本（当结合更多的硬件）能够增加搜索吞吐率。 协调节点将在之后的请求中轮询所有的分片拷贝来分摊负载。
每个分片在本地执行查询请求并且创建一个长度为 from + size 的优先队列—也就是说，每个分片创建的结果集足够大，均可以满足全局的搜索请求。 
分片返回一个轻量级的结果列表到协调节点，它仅包含文档 ID 集合以及任何排序需要用到的值，例如 _score 。
协调节点将这些分片级的结果合并到自己的有序优先队列里，它代表了全局排序结果集合。至此查询过程结束。
```

# 




